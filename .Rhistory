###
set.seed(100)
data_group <- data_clean_1 %>%
mutate(group = sample(1:5, nrow(.), replace = TRUE))
individuals <- data_clean_1 %>%
pull(individual) %>%
unique()
table_all <- matrix(0, nrow = length(individuals), ncol = length(individuals))
for (i in 1:5) {
# split training data and test data
data_train <- data_group %>%
filter(group != i)
data_test <- data_group %>%
filter(group == i)
# data pre-processing
preproc.param <- data_train %>%
preProcess(method = c("center", "scale"))
train_transformed <- preproc.param %>% predict(data_train)
test_transformed <- preproc.param %>% predict(data_test)
# model fitting
model <- train_transformed %>%
select(individual, sl, i2, i3, duration_8, meandom_6, meandom_1,
meandom_8, duration_3, duration_2) %>%
lda(individual ~ ., data = .)
# model evaluation
predictions <- model %>% predict(test_transformed)
observed <- test_transformed$individual %>%
as_factor()
levels(observed) <- individuals
predicted <- predictions$class %>%
as_factor()
levels(predicted) <- individuals
table_i <- table(predicted, observed)
table_all <- table_all + table_i
}
table_all_cm <- confusionMatrix(table_all)
accuracy <- table_all_cm$overall[1]
kappa <- table_all_cm$overall[2]
# variable selection
train_transformed %>%
greedy.wilks(individual ~ sl + i1 + i2 + i3 + min_d + max_d +
duration_1 + duration_2 + duration_3 + duration_4 +
duration_5 + duration_6 + duration_7 + duration_8 +
dfrange_1 + dfrange_2 + dfrange_3 + dfrange_4 +
dfrange_5 + dfrange_6 + dfrange_7 + dfrange_8 +
meandom_1 + meandom_2 + meandom_3 + meandom_4 +
meandom_5 + meandom_6 + meandom_7 + meandom_8
, data = .)
# visualization
lda_data <- cbind(train_transformed, predict(model)$x)
ggplot(lda_data, aes(LD1, LD2)) +
geom_point(aes(color = individual))
ggord(model, data_train$site, arrow = NULL, txt = NULL) +
coord_fixed(ratio = 0.7)
colnames(df) <- c("x", "y", "value")
ggplot(df, aes(x = x, y = y, fill = value)) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed()
df
df <- melt(table_all_cm$table)
library(reshape2)
df <- melt(table_all_cm$table)
colnames(df) <- c("x", "y", "value")
ggplot(df, aes(x = x, y = y, fill = value)) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed()
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed()
###
### Library
###
library(here)
library(tidyverse)
library(lubridate)
library(sf)
library(leaflet)
library(factoextra)
library(ggbiplot)
library(corrplot)
library(psych)
library(caret)
library(MASS)
# avoid name overwrite
here <- here::here
select <- dplyr::select
filter <- dplyr::filter
summarize <- dplyr::summarize
group_by <- dplyr::group_by
rename <- dplyr::rename
###
### Data import and cleaning
###
# the original output from BirdNET
data_raw <- read_csv(here("data", "barred_owl_recordings_list.csv"))
data_raw_clean <- data_raw %>%
filter(year == 2021) %>%
drop_na() %>%
mutate(date = ymd(paste0(year, month, day)),
hour = str_sub(recording, start = 10, end = 11),
Julian = yday(date),
day_period = cut(Julian,
breaks = c(40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150)))
# the song dataset after manual extraction of features
data <- read_csv(here("data", "barred_owl_recordings_list_parameters_2.csv"))
data_clean <- data %>%
filter_all(all_vars(. != 0)) %>%
mutate(site = str_sub(sound.files, start = 1, end = 5),
year = str_sub(sound.files, start = 7, end = 10),
month = str_sub(sound.files, start = 11, end = 12),
day = str_sub(sound.files, start = 13, end = 14),
unique_ID = seq(from = 1, to = nrow(.)),
individual = paste0(year, "_", site),
date = ymd(paste0(year, month, day)))
sites <- data_clean %>%
group_by(site) %>%
summarize(n = n()) %>%
filter(n >= 9) %>%
pull(site)
data_clean_1 <- data_clean %>%
filter(site %in% sites)
###
### Main analysis
###
set.seed(100)
data_group <- data_clean_1 %>%
mutate(group = sample(1:5, nrow(.), replace = TRUE))
data_group <- data_clean_1 %>%
mutate(group = sample(1:5, nrow(.), replace = TRUE))
individuals <- data_clean_1 %>%
pull(individual) %>%
unique()
table_all <- matrix(0, nrow = length(individuals), ncol = length(individuals))
for (i in 1:5) {
# split training data and test data
data_train <- data_group %>%
filter(group != i)
data_test <- data_group %>%
filter(group == i)
# data pre-processing
preproc.param <- data_train %>%
preProcess(method = c("center", "scale"))
train_transformed <- preproc.param %>% predict(data_train)
test_transformed <- preproc.param %>% predict(data_test)
# model fitting
model <- train_transformed %>%
select(individual, sl, i2, i3, duration_8, meandom_6, meandom_1,
meandom_8, duration_3, duration_2) %>%
lda(individual ~ ., data = .)
# model evaluation
predictions <- model %>% predict(test_transformed)
observed <- test_transformed$individual %>%
as_factor()
levels(observed) <- individuals
predicted <- predictions$class %>%
as_factor()
levels(predicted) <- individuals
table_i <- table(predicted, observed)
table_all <- table_all + table_i
}
table_all_cm <- confusionMatrix(table_all)
accuracy <- table_all_cm$overall[1]
kappa <- table_all_cm$overall[2]
accuracy
kappa
# visualization
lda_data <- cbind(train_transformed, predict(model)$x)
ggplot(lda_data, aes(LD1, LD2)) +
geom_point(aes(color = individual))
ggord(model, data_train$site, arrow = NULL, txt = NULL) +
coord_fixed(ratio = 0.7)
library(ggord)
ggord(model, data_train$site, arrow = NULL, txt = NULL) +
coord_fixed(ratio = 0.7)
df <- melt(table_all_cm$table)
colnames(df) <- c("x", "y", "value")
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed()
df <- melt(table_all_cm$table)
library(reshape2)
df <- melt(table_all_cm$table)
colnames(df) <- c("x", "y", "value")
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed()
log(0)
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.5, hjust=1))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.2, hjust=0.5))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.1, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.5, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.3, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.4, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.5, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.2, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.2, hjust=0.4))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.2, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.2, hjust=0.1))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.2, hjust=0.7))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.9, hjust=0.7))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.1, hjust=0.2))
ggplot(df, aes(x = x, y = y, fill = value %>% log())) +
geom_tile(color = "white",
lwd = 1.5,
linetype = 1) +
coord_fixed() +
theme(axis.text.x = element_text(angle = 60, vjust = 0.1, hjust = 0.2))
log(10)
log(2)
log(e)
log(exp())
log(exp(1))
exp(0)
exp(1)
exp(2)
exp(3)
exp(4)
exp(5)
###
### Library
###
library(here)
library(tidyverse)
library(lubridate)
library(sf)
library(leaflet)
library(factoextra)
library(ggbiplot)
library(corrplot)
library(psych)
library(caret)
library(MASS)
# avoid name overwrite
here <- here::here
select <- dplyr::select
filter <- dplyr::filter
summarize <- dplyr::summarize
group_by <- dplyr::group_by
rename <- dplyr::rename
###
### Data import and cleaning
###
# the original output from BirdNET
data_raw <- read_csv(here("data", "barred_owl_recordings_list.csv"))
data_raw_clean <- data_raw %>%
filter(year == 2021) %>%
drop_na() %>%
mutate(date = ymd(paste0(year, month, day)),
hour = str_sub(recording, start = 10, end = 11),
Julian = yday(date),
day_period = cut(Julian,
breaks = c(40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150)))
# the song dataset after manual extraction of features
data <- read_csv(here("data", "barred_owl_recordings_list_parameters_2.csv"))
data_clean <- data %>%
filter_all(all_vars(. != 0)) %>%
mutate(site = str_sub(sound.files, start = 1, end = 5),
year = str_sub(sound.files, start = 7, end = 10),
month = str_sub(sound.files, start = 11, end = 12),
day = str_sub(sound.files, start = 13, end = 14),
unique_ID = seq(from = 1, to = nrow(.)),
individual = paste0(year, "_", site),
date = ymd(paste0(year, month, day)))
sites <- data_clean %>%
group_by(site) %>%
summarize(n = n()) %>%
filter(n >= 9) %>%
pull(site)
data_clean_1 <- data_clean %>%
filter(site %in% sites)
# location of the 66 sites
location <- read_csv(here("data", "JPRF_all_sites.csv"))
location_clean <- location %>%
rename("site" = Name, "longitude" = X, "latitude" = Y) %>%
select(site, longitude, latitude) %>%
mutate(group = str_extract(site, pattern = ".+(?=\\_)"))
###
### Library
###
library(here)
# spatial distribution of the ARUs and the songs in each sites that is going to be analyzed
JPRF_sf <- full_join(location_clean,
data_clean_1 %>%
group_by(site) %>%
summarize(n_songs = n()),
by = "site", replace_na) %>%
replace_na(list(n_songs = 0)) %>%
st_as_sf(coords = c("longitude", "latitude"), crs = 4326)
JPRF_sf
JPRF_sf <- full_join(location_clean,
data_clean_1 %>%
group_by(site) %>%
summarize(n_songs = n()),
by = "site", replace_na) %>%
replace_na(list(n_songs = 0))
JPRF_sf
JPRF_sf <- full_join(location_clean,
data_clean_1 %>%
group_by(site) %>%
summarize(n_songs = n()),
by = "site", replace_na) %>%
replace_na(list(n_songs = 0))
JPRF_sf
dist(JPRF_sf %>% pull(longitude, latitude), method="euclidean", diag=TRUE,
upper=FALSE)
rownames(JPRF_sf)
rownames(JPRF_sf) <- JPRF_sf$site
rownames(JPRF_sf)
JPRF_sf <- JPRF_sf %>%
pull(longitude, latitude) %>%
as.matrix()
dist(JPRF_sf, method="euclidean", diag=TRUE,
upper=FALSE)
JPRF_sf <- full_join(location_clean,
data_clean_1 %>%
group_by(site) %>%
summarize(n_songs = n()),
by = "site", replace_na) %>%
replace_na(list(n_songs = 0))
rownames(JPRF_sf) <- JPRF_sf$site
JPRF_sf <- JPRF_sf %>%
pull(longitude, latitude) %>%
as.matrix()
JPRF_sf
A1 <- c(0, 0)
B1 <- c(0.85, 0)
C1 <- c(0.85, 0.45)
D1 <- c(0, 0.45)
#making a single matrix
CooR <- rbind(A1, B1, C1, D1)
CooR
JPRF_sf <- full_join(location_clean,
data_clean_1 %>%
group_by(site) %>%
summarize(n_songs = n()),
by = "site", replace_na) %>%
replace_na(list(n_songs = 0))
JPRF_sf_m <- JPRF_sf %>%
pull(longitude, latitude) %>%
as.matrix()
rownames(JPRF_sf_m) <- JPRF_sf$site
dist(JPRF_sf, method="euclidean", diag=TRUE,
upper=FALSE)
JPRF_sf_m
JPRF_sf_m <- JPRF_sf %>%
pull(longitude, latitude)
JPRF_sf_m
JPRF_sf
JPRF_sf_m <- JPRF_sf %>%
pull(longitude, latitude)
JPRF_sf_m
JPRF_sf_m <- JPRF_sf %>%
select(longitude, latitude) %>%
as.matrix()
rownames(JPRF_sf_m) <- JPRF_sf$site
dist(JPRF_sf, method="euclidean", diag=TRUE,
upper=FALSE)
JPRF_sf_m
#making a single matrix
CooR <- rbind(A1, B1, C1, D1)
CooR
CooR <- rbind(A1, B1, C1, D1)
dist(CooR, method="euclidean", diag=TRUE,
upper=FALSE)
dist(JPRF_sf_m, method="euclidean", diag=TRUE,
upper=FALSE)
###
### Main analysis
###
set.seed(100)
data_group <- data_clean_1 %>%
mutate(group = sample(1:5, nrow(.), replace = TRUE))
individuals <- data_clean_1 %>%
pull(individual) %>%
unique()
table_all <- matrix(0, nrow = length(individuals), ncol = length(individuals))
for (i in 1:5) {
# split training data and test data
data_train <- data_group %>%
filter(group != i)
data_test <- data_group %>%
filter(group == i)
# data pre-processing
preproc.param <- data_train %>%
preProcess(method = c("center", "scale"))
train_transformed <- preproc.param %>% predict(data_train)
test_transformed <- preproc.param %>% predict(data_test)
# model fitting
model <- train_transformed %>%
select(individual, sl, i2, i3, duration_8, meandom_6, meandom_1,
meandom_8, duration_3, duration_2) %>%
lda(individual ~ ., data = .)
# model evaluation
predictions <- model %>% predict(test_transformed)
observed <- test_transformed$individual %>%
as_factor()
levels(observed) <- individuals
predicted <- predictions$class %>%
as_factor()
levels(predicted) <- individuals
table_i <- table(predicted, observed)
table_all <- table_all + table_i
}
table_all_cm <- confusionMatrix(table_all)
accuracy <- table_all_cm$overall[1]
kappa <- table_all_cm$overall[2]
# variable selection
train_transformed %>%
greedy.wilks(individual ~ sl + i1 + i2 + i3 + min_d + max_d +
duration_1 + duration_2 + duration_3 + duration_4 +
duration_5 + duration_6 + duration_7 + duration_8 +
dfrange_1 + dfrange_2 + dfrange_3 + dfrange_4 +
dfrange_5 + dfrange_6 + dfrange_7 + dfrange_8 +
meandom_1 + meandom_2 + meandom_3 + meandom_4 +
meandom_5 + meandom_6 + meandom_7 + meandom_8
, data = .)
# visualization
lda_data <- cbind(train_transformed, predict(model)$x)
lda_data
lda_datastr(lda_data)
str(lda_data)
test <- lda_data %>%
group_by(individual) %>%
summarize(LD1_mean = mean(LD1),
LD2_mean = mean(LD2))
test
